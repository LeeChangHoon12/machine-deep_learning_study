{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-4810c9d49390>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/user/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/user/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/user/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/user/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "True 55000\n",
      "True 5000\n",
      "True 10000\n",
      "image shape : (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "## Data load\n",
    "##train, validation, test set\n",
    "##check data\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",reshape=False)\n",
    "\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "\n",
    "x_validation = mnist.validation.images\n",
    "y_validation = mnist.validation.labels\n",
    "\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "print(len(x_train)==len(y_train),len(x_train))\n",
    "print(len(x_validation)==len(y_validation),len(x_validation))\n",
    "print(len(x_test)==len(y_test),len(x_test))\n",
    "\n",
    "print(\"image shape : {}\".format(x_train[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape : (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "## mnist images = 28*2*1\n",
    "## LeNet input images = 32*32*color channels\n",
    "## np.pad => top,bottom,right,letf padding\n",
    "\n",
    "x_train = np.pad(x_train,((0,0),(2,2),(2,2),(0,0)),'constant')\n",
    "x_validation = np.pad(x_validation,((0,0),(2,2),(2,2),(0,0)),'constant')\n",
    "x_test = np.pad(x_test,((0,0),(2,2),(2,2),(0,0)),'constant')\n",
    "\n",
    "print(\"image shape : {}\".format(x_train[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0,len(x_train))\n",
    "image = x_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image,cmap=\"gray\")\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5 \n",
    "# input = 32*32*c images\n",
    "# Layer1 conv(output 28*28*6) => activation => pooling(14*14*6)\n",
    "# Layer2 conv(output 10*10*16) => activation => pooling(5*5*16)\n",
    "# flatten\n",
    "# fully connect -> 120 outputs\n",
    "# activation\n",
    "# fully connect -> 84 outputs\n",
    "# activation\n",
    "# fully connect -> (logits) = 10 outputs\n",
    "\n",
    "\n",
    "\n",
    "## average pooling -> max pooling\n",
    "## sigmoid -> relu !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "# LeNet class\n",
    "\n",
    "def LeNet5(x):\n",
    "    # layer 1 : conv // input 32*32*1 // output 28*28*6\n",
    "    conv1_w = tf.Variable(tf.random_normal(shape=[5,5,1,6]))\n",
    "    conv1_b = tf.Variable(tf.random_normal(shape=[6]))\n",
    "    conv1 = tf.nn.conv2d(x,conv1_w, strides = [1,1,1,1], padding = 'VALID') + conv1_b\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    \n",
    "    # pooling // input 28*28*8 // output = 14*14*6\n",
    "    pool_1 = tf.nn.max_pool(conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "    \n",
    "    # layer 2 : conv // input 14*14*6 // output 10*10*16\n",
    "    conv2_w = tf.Variable(tf.random_normal(shape=[5,5,6,16]))\n",
    "    conv2_b = tf.Variable(tf.random_normal(shape=[16]))\n",
    "    conv2 = tf.nn.conv2d(pool_1,conv2_w,strides=[1,1,1,1],padding='VALID') + conv2_b\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    print(conv2.shape)\n",
    "    # pooling // input 10*10*16 // ouput 5*5*16\n",
    "    pool_2 = tf.nn.max_pool(conv2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID') \n",
    "    \n",
    "    #flatten input 5*5*16 output 400\n",
    "    fc1 = flatten(pool_2)\n",
    "    print(fc1.shape)\n",
    "    # layer 3 : Fully connected. input 400 output 120\n",
    "    fc1_w = tf.Variable(tf.random_normal([400,120]))\n",
    "    fc1_b = tf.Variable(tf.random_normal([120]))\n",
    "\n",
    "    fc1 = tf.matmul(fc1,fc1_w) + fc1_b\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    #layer 4 : Fulliy connected input 120 output 84\n",
    "    fc2_w = tf.Variable(tf.random_normal([120,84]))\n",
    "    fc2_b = tf.Variable(tf.random_normal([84]))\n",
    "    \n",
    "    fc2 = tf.matmul(fc1,fc2_w) + fc2_b\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    \n",
    "    #layer 5 : Fulliy connected input 84 output 10\n",
    "    fc3_w = tf.Variable(tf.random_normal([84,10]))\n",
    "    fc3_b = tf.Variable(tf.random_normal([10]))\n",
    "    \n",
    "    logits = tf.matmul(fc2,fc3_w) + fc3_b\n",
    "    \n",
    "    return logits                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,(None,32,32,1))\n",
    "y = tf.placeholder(tf.int32,(None))\n",
    "one_hot_y = tf.one_hot(y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10, 10, 16)\n",
      "WARNING:tensorflow:From /Users/user/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /Users/user/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "(?, 400)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_4:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LeNet5(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10, 10, 16)\n",
      "(?, 400)\n",
      "WARNING:tensorflow:From <ipython-input-11-bcf6b4e38c88>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "logits = LeNet5(x)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=one_hot_y))\n",
    "training = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(x_data, y_data):\n",
    "    num_examples = len(x_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, batch_size):\n",
    "        batch_x, batch_y = x_data[offset:offset+batch_size], y_data[offset:offset+batch_size]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.916\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.945\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.954\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.958\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.960\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.966\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.968\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.968\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.968\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "accu_list = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(x_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(epoch):\n",
    "        x_train, y_train = shuffle(x_train, y_train)\n",
    "        for offset in range(0, num_examples, batch_size):\n",
    "            end = offset + batch_size\n",
    "            batch_x, batch_y = x_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(x_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        accu_list.append(validation_accuracy)\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "Test Accuracy = 0.968\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(x_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
